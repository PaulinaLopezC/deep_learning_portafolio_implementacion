{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "2gAUiiNoiCtM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install \"tensorflow-text==2.19.*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mQkn2rnsG-jz",
        "outputId": "973f7040-762b-4354-c706-66d596d362aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-text==2.19.* in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-text==2.19.*) (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text==2.19.*) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Importamos dataset de train y validation y vocabulario**"
      ],
      "metadata": {
        "id": "UlBPg8tz5H6R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QBbomi7E6Cg",
        "outputId": "aa7fa47c-3da4-4139-b8a5-64f019b156dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Montar Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Ruta base\n",
        "base_dir = \"/content/gdrive/MyDrive/ESCUELA/IRS/7MO/IA-2/Modulo-2.2/EVIDENCIA/prepared_datasets\"\n",
        "\n",
        "# Cargar datasets\n",
        "train_dataset = tf.data.Dataset.load(os.path.join(base_dir, \"train_dataset\"))\n",
        "val_dataset   = tf.data.Dataset.load(os.path.join(base_dir, \"val_dataset\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimimos un ejemplo de como se ven los datasets"
      ],
      "metadata": {
        "id": "3xsA4gcC5QGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for example in train_dataset.take(1):\n",
        "    print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1XV9QsOmFAC2",
        "outputId": "954f770e-2a83-4bd0-9e26-19c04f79db7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(32, 250), dtype=int64, numpy=\n",
            "array([[  81,  172,  210, ...,   33,  977,    3],\n",
            "       [   2, 1613,   81, ...,  150,  169,  327],\n",
            "       [1374,   60,  110, ..., 5886,  538,  117],\n",
            "       ...,\n",
            "       [   2,   33,   70, ...,    0,    0,    0],\n",
            "       [ 327,   97,  755, ...,    0,    0,    0],\n",
            "       [   2, 1758,  143, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
            "array([1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
            "       0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for example in val_dataset.take(1):\n",
        "    print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jQT-lDH9FCWK",
        "outputId": "e58e8613-6518-43fa-af29-2e8d45f6bb0d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(32, 250), dtype=int64, numpy=\n",
            "array([[    2,  1777,   106, ...,   413,   167,   538],\n",
            "       [  551,    36,   221, ...,     7,   139,     5],\n",
            "       [11395,  2134,    22, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [ 1048,  1792,     5, ...,     0,     0,     0],\n",
            "       [    2,    85,   481, ...,  4508,     4,     2],\n",
            "       [   69,    17,    18, ...,     4,    93,   151]])>, <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
            "array([1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos vocabulario"
      ],
      "metadata": {
        "id": "sj6HV2UG5ZHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_path = os.path.join(base_dir, \"vocab.txt\")\n",
        "\n",
        "with open(vocab_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    vocab = [line.strip() for line in f]"
      ],
      "metadata": {
        "id": "pU5k77qsFESv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vocabulario lo convertimos en un array para usarlo en el modelo"
      ],
      "metadata": {
        "id": "Cq3NytQ35bPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "vocab = np.array(vocab)\n",
        "vocab[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dol01BUK-Hnz",
        "outputId": "877c4bca-11a0-4dd3-ab5c-ff526bb3271a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'to', 'of', 'a', 'and', 'in', 'that', 'on',\n",
              "       's', 'for', 'is', 'said', 'he', 'it', 'with', 'trump', 'was', 'as'],\n",
              "      dtype='<U46')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revisamos el dataset de train y val para saber cuales son los valores maximos y minimos del vocabulario y asi ajustar el modelo a esos limites."
      ],
      "metadata": {
        "id": "k6bFJ3Hb5goz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def get_id_bounds(ds, take=None):\n",
        "    min_id = None\n",
        "    max_id = None\n",
        "    n = 0\n",
        "    for x, _ in (ds.take(take) if take else ds):\n",
        "        x = tf.convert_to_tensor(x)\n",
        "        cur_min = int(tf.reduce_min(x))\n",
        "        cur_max = int(tf.reduce_max(x))\n",
        "        min_id = cur_min if min_id is None else min(min_id, cur_min)\n",
        "        max_id = cur_max if max_id is None else max(max_id, cur_max)\n",
        "        n += 1\n",
        "    return min_id, max_id, n\n",
        "\n",
        "min_tr, max_tr, ntr = get_id_bounds(train_dataset)\n",
        "min_va, max_va, nva = get_id_bounds(val_dataset)\n",
        "\n",
        "min_id = min(min_tr, min_va)\n",
        "max_id = max(max_tr, max_va)\n",
        "\n",
        "print(\"min_id:\", min_id, \"max_id:\", max_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBc4UNHa_Z53",
        "outputId": "b6595471-8166-4ead-a8a7-384abfb3765b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_id: 0 max_id: 19999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = max_id + 1\n",
        "use_mask_zero = (min_id == 0)"
      ],
      "metadata": {
        "id": "NMheRRNbT0mu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Arquitectura del modelo**"
      ],
      "metadata": {
        "id": "HWISZXo96nhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos arquitectura para el modelo usando capas como:\n",
        "- Embedding (tranformación de vectores a valores que pueda ajustar el modelo),\n",
        "- Bidirectional (Red neuronal recurrente para generar memoria)\n",
        "- Capas densas (con funciones de activacion)\n",
        "\n",
        "Metodos de regularizacion como:\n",
        "- dropout(apagan neuronas de manera temporal),"
      ],
      "metadata": {
        "id": "QmbqfyuR6tUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=input_dim, output_dim=64, mask_zero=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout=0.1, recurrent_dropout=0.1)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "VaaGvECeJxAJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos guardar el modelo"
      ],
      "metadata": {
        "id": "-FU1NXMB7azX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "save_path = \"/content/gdrive/MyDrive/ESCUELA/IRS/7MO/IA-2/Modulo-2.2/EVIDENCIA\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Guardar modelo completo\n",
        "model_path = os.path.join(save_path, \"modelo_final.keras\")"
      ],
      "metadata": {
        "id": "yh-d1utjJ7SZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui definimos que metricas vamos a usar para medir el desempeño del entrenamiento.\n",
        "\n",
        "Y definimmos tambien funciones como:\n",
        "- Early stop (detener el entrenamiento cuando no encuentra una mejora considerable en, este caso, la perdida de validation)\n",
        "- Checkpoint (Guardar los pesos del modelo cuando este mejore a partir de sus metricas)"
      ],
      "metadata": {
        "id": "XgZBhstD7drl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "model2.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # LR normal\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=model_path,\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "g5v9B0qaJ3UX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el entrenamiento del modelo:\n",
        "- Con que dataset va a entrenar\n",
        "- Numero de epochs\n",
        "- Con que dataset va a validar\n",
        "- Si tiene alguna funcion para callback (early stop, checkpoint)"
      ],
      "metadata": {
        "id": "YMxiZYyI8Aej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWYSOIbjJ9_f",
        "outputId": "78e563c2-8dca-40b2-9e50-3c1edea4a0f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8771 - loss: 0.2579\n",
            "Epoch 1: val_loss improved from inf to 0.06653, saving model to /content/gdrive/MyDrive/ESCUELA/IRS/7MO/IA-2/Modulo-2.2/EVIDENCIA/modelo_final.keras\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1204s\u001b[0m 2s/step - accuracy: 0.8772 - loss: 0.2578 - val_accuracy: 0.9809 - val_loss: 0.0665\n",
            "Epoch 2/15\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9875 - loss: 0.0441\n",
            "Epoch 2: val_loss improved from 0.06653 to 0.05220, saving model to /content/gdrive/MyDrive/ESCUELA/IRS/7MO/IA-2/Modulo-2.2/EVIDENCIA/modelo_final.keras\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1182s\u001b[0m 2s/step - accuracy: 0.9875 - loss: 0.0441 - val_accuracy: 0.9833 - val_loss: 0.0522\n",
            "Epoch 3/15\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9954 - loss: 0.0170\n",
            "Epoch 3: val_loss did not improve from 0.05220\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1181s\u001b[0m 2s/step - accuracy: 0.9954 - loss: 0.0170 - val_accuracy: 0.9747 - val_loss: 0.0756\n",
            "Epoch 4/15\n",
            "\u001b[1m 44/656\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:29\u001b[0m 2s/step - accuracy: 0.9969 - loss: 0.0142"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra manera de guardar el modelo cuando termine de entrenarse"
      ],
      "metadata": {
        "id": "xuzlJY6T8RoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"/content/gdrive/MyDrive/ESCUELA/IRS/7MO/IA-2/Modulo-2.2/EVIDENCIA/modelo_prueba.keras\"\n",
        "model_path = os.path.join(dir, \"feeling_model_2.keras\")\n",
        "model2.save(model_path)\n",
        "\n",
        "print(f\"Modelo guardado correctamente en: {model_path}\")"
      ],
      "metadata": {
        "id": "PZOtsbMFFG7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluamos el modelo con el dataset de validation"
      ],
      "metadata": {
        "id": "M2cUmGuj8Vj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model2.evaluate(val_dataset)\n",
        "\n",
        "print('Test Loss:', val_loss)\n",
        "print('Test Accuracy:', val_acc)"
      ],
      "metadata": {
        "id": "BpwNFARcKCi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimimos las metricas en una tabla para ver la diferencia del desempeño del dataset de train y de validation"
      ],
      "metadata": {
        "id": "-LOKsMlZ8Yfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.ylim(None, 1)\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history, 'loss')\n",
        "plt.ylim(0, None)"
      ],
      "metadata": {
        "id": "7ovrIi-KKEmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estar predicciones fueron de prueba antes de intentar hacer predicciones en otro noteboook"
      ],
      "metadata": {
        "id": "zzJxUm5l3Zbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PREDICCIONES"
      ],
      "metadata": {
        "id": "2gAUiiNoiCtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import json\n",
        "\n",
        "with open(vocab_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw = [line.rstrip(\"\\n\\r\") for line in f]\n",
        "\n",
        "raw = [tok.strip() for tok in raw]\n",
        "\n",
        "seen = set()\n",
        "vocab = []\n",
        "dups = []\n",
        "for tok in raw:\n",
        "    if tok == \"\" or tok is None:\n",
        "        dups.append(\"<BLANK>\")\n",
        "        continue\n",
        "    if tok in seen:\n",
        "        dups.append(tok)\n",
        "        continue\n",
        "    seen.add(tok)\n",
        "    vocab.append(tok)\n",
        "\n",
        "print(f\"Se removieron {len(dups)} entradas problemáticas (mostrando algunas): {dups[:10]}\")\n",
        "\n",
        "encoder = layers.TextVectorization(\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=500,\n",
        "    vocabulary=vocab,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj2iH2K9CGpb",
        "outputId": "20a4b1f5-1928-4eb7-fbb5-9e055169f70a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se removieron 5 entradas problemáticas (mostrando algunas): ['<BLANK>', '<BLANK>', '<BLANK>', '<BLANK>', 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "encoder = layers.TextVectorization(\n",
        "    output_sequence_length=100,   # la misma longitud usada al entrenar\n",
        "    vocabulary=vocab              # el mismo vocab (mismo orden, sin deduplicar/insertar)\n",
        ")"
      ],
      "metadata": {
        "id": "eALkURi6eRZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARRAFOS"
      ],
      "metadata": {
        "id": "goG88Q54fFdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = tf.constant([\n",
        "    \"Former NASA scientist Dr. Leonard Carmichael announced on Thursday that a hidden city has been discovered beneath the surface of Antarctica using satellite radar imaging. According to preliminary reports, the structures resemble ancient pyramids aligned with celestial constellations, leading some researchers to believe that the ruins could predate all known human civilizations. The discovery, allegedly made by a joint U.S.-European research mission, has been kept secret by world governments due to “potential geopolitical consequences.” Dr. Carmichael claimed that the team uncovered symmetrical walls, tunnels, and chambers nearly two miles below the ice sheet, suggesting that the area was once free of ice thousands of years ago. “This changes everything we know about human history,” he said during a private scientific symposium in Geneva. Several conspiracy theorists quickly linked the finding to theories of advanced prehistoric societies and alien intervention. NASA and the European Space Agency, however, have declined to comment publicly, fueling even more speculation. Social media users have circulated supposed leaked images of the subterranean site, showing geometric patterns and metallic structures. Critics argue that the photos are digitally manipulated and that the radar data was misinterpreted. Still, many online forums insist that an official announcement will come “within the year,” revealing the existence of an advanced ancient civilization under Antarctica’s ice.\"\n",
        "])\n",
        "X = encoder(texts)          # -> ints shape (batch, seq_len)\n",
        "probs = model2.predict(X)\n",
        "preds = (probs >= 0.5).astype(int)\n",
        "print(probs.ravel(), preds.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I1Yj9EueRtl",
        "outputId": "2a543962-853f-4ef3-97dd-59ec0556352c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "[0.80559283] [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = tf.constant([\n",
        "    \"The European Space Agency (ESA) announced on Tuesday that its Gaia space observatory has mapped over 1.8 billion stars in the Milky Way, creating the most detailed 3D chart of our galaxy ever produced. Launched in 2013, Gaia’s mission is to precisely measure the position, distance, and motion of stars, providing astronomers with an unprecedented view of the Milky Way’s structure and evolution. The new dataset, released in 2024, includes not only stars but also information about asteroids, quasars, and distant galaxies. “This is the most complete map of our cosmic neighborhood,” said Timo Prusti, Gaia’s project scientist. Researchers are using the data to track how the Milky Way has changed over billions of years and to study how stars migrate through space. The catalog also contains details on the chemical composition of stars, helping scientists understand how heavy elements were formed in earlier generations of stellar evolution. The ESA expects Gaia’s findings to benefit several branches of astronomy, from exoplanet detection to dark matter research. With each new data release, the observatory continues to refine our understanding of the universe, confirming its status as one of the most ambitious and successful missions in modern astrophysics.\"\n",
        "])\n",
        "X = encoder(texts)          # -> ints shape (batch, seq_len)\n",
        "probs = model2.predict(X)\n",
        "preds = (probs >= 0.5).astype(int)\n",
        "print(probs.ravel(), preds.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG9w4tTvegSD",
        "outputId": "579630f9-f605-48f9-d83a-c30f1092a017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
            "[0.0026601] [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ORACIONES"
      ],
      "metadata": {
        "id": "koJvZs66fHhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FALSA"
      ],
      "metadata": {
        "id": "7ZNV173Sfo63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = tf.constant([\n",
        "    \"Scientists from the International Space Research Agency have announced that the Moon will turn completely green next month due to a rare combination of cosmic radiation and atmospheric particles. Experts recommend taking pictures, as this event supposedly happens only once every 500 years.\"\n",
        "])\n",
        "X = encoder(texts)          # -> ints shape (batch, seq_len)\n",
        "probs = model2.predict(X)\n",
        "preds = (probs >= 0.5).astype(int)\n",
        "print(probs.ravel(), preds.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeRd_EsqfDFn",
        "outputId": "42397eb6-49c3-495f-be89-6e581e430938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "[0.00098412] [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REAL"
      ],
      "metadata": {
        "id": "yzGjkI6Pft66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = tf.constant([\n",
        "    \"NASA’s James Webb Space Telescope captured detailed images of a distant galaxy, NGC 346, revealing new insights into star formation. The data, released in 2024, show young stars surrounded by clouds of gas and dust, helping scientists understand how galaxies evolve over time.\"\n",
        "])\n",
        "X = encoder(texts)          # -> ints shape (batch, seq_len)\n",
        "probs = model2.predict(X)\n",
        "preds = (probs >= 0.5).astype(int)\n",
        "print(probs.ravel(), preds.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqsU6IR-fTfo",
        "outputId": "59f6aa1a-7204-49f8-8acb-0dfbd70c14d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "[0.11404935] [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FALSA DIFICIL"
      ],
      "metadata": {
        "id": "L_A0SX0Cf0Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = tf.constant([\n",
        "    \"A new study claims that drinking two cups of coffee before bed can improve sleep quality and memory retention. Researchers allegedly found that caffeine helps the brain relax and promotes deeper rest phases during the night.\"\n",
        "])\n",
        "X = encoder(texts)          # -> ints shape (batch, seq_len)\n",
        "probs = model2.predict(X)\n",
        "preds = (probs >= 0.5).astype(int)\n",
        "print(probs.ravel(), preds.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuYjTu1Yfzbi",
        "outputId": "91abaff6-5f6f-4e51-f9bb-58e1e6a04b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "[0.15384884] [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REAL AMBIGUA"
      ],
      "metadata": {
        "id": "X9IEzNb6fvTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = tf.constant([\n",
        "    \"Researchers from Stanford University reported a potential link between smartphone usage at night and increased anxiety levels among young adults. Although the findings are not yet peer-reviewed, the study suggests that screen exposure before sleep might influence emotional regulation.\"\n",
        "])\n",
        "X = encoder(texts)          # -> ints shape (batch, seq_len)\n",
        "probs = model2.predict(X)\n",
        "preds = (probs >= 0.5).astype(int)\n",
        "print(probs.ravel(), preds.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpYbVN4TevIP",
        "outputId": "54043be1-7300-4d65-b7fa-5271e80bb15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "[0.9687968] [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = tf.constant([\n",
        "    \"The International Energy Agency (IEA) reported on Wednesday that global renewable energy capacity grew by a record 510 gigawatts in 2024, marking the fastest expansion in history. According to the agency’s annual review, solar and wind power accounted for nearly 90% of new installations, driven largely by investments in China, the United States, and the European Union. The IEA noted that renewable sources now represent about 42% of total global electricity generation. Executive Director Fatih Birol emphasized that the growth shows the world is “moving decisively toward a cleaner and more secure energy future,” although he cautioned that more policy efforts are needed to meet the Paris Agreement climate goals. The report also highlighted that battery storage capacity doubled in 2024, reflecting rapid innovation in grid technology and energy efficiency.\"\n",
        "])\n",
        "X = encoder(texts)          # -> ints shape (batch, seq_len)\n",
        "probs = model2.predict(X)\n",
        "preds = (probs >= 0.5).astype(int)\n",
        "print(probs.ravel(), preds.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM9lID31gJOr",
        "outputId": "54e65e3e-f28a-45c4-dd27-a41384d11bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
            "[0.98669094] [1]\n"
          ]
        }
      ]
    }
  ]
}